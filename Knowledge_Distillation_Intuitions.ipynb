{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPHKGBiJQcXK+S1t+6w7csA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mridul-sahu/knowledge_distillation_intuitions/blob/main/Knowledge_Distillation_Intuitions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intuitive Knowledge Distillation: From Teacher to Student with JAX and FLAX NNX\n",
        "\n",
        "**Goal:** This notebook provides a clear, step-by-step guide to understanding and implementing various knowledge distillation techniques. We'll use JAX for high-performance computation, FLAX (specifically the new NNX API) for building neural networks with a more explicit stateful feel, and Optax for optimization. Our focus will be on building intuition for *why* and *how* each distillation method works, using the CIFAR-10 dataset as our playground.\n",
        "\n",
        "**What you'll learn:**\n",
        "* The core concepts of knowledge distillation.\n",
        "* How to define and train models using FLAX NNX.\n",
        "* How to implement baseline teacher and student models.\n",
        "* How to apply standard knowledge distillation (matching output logits).\n",
        "* How to use `flax.nnx.Intermediate` to capture and use intermediate model representations for more advanced distillation techniques like:\n",
        "    * Matching hidden state representations using Cosine Similarity.\n",
        "    * Using an intermediate regressor (FitNets-style) with MSE loss.\n",
        "* How to manage state, parameters, and RNGs in FLAX NNX.\n",
        "\n",
        "**Acknowlegement**\n",
        "* This tutorial is a translation of https://docs.pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html in JAX and FLAX NNX."
      ],
      "metadata": {
        "id": "kQPT_U0tvMMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Introduction & Setup\n",
        "\n",
        "### 0.1. A Quick Word on JAX, FLAX NNX, and Optax\n",
        "\n",
        "* **JAX:** JAX is a Python library for high-performance numerical computation, especially popular for machine learning research. It combines NumPy's familiar API with automatic differentiation (`jax.grad`), composition of function transformations (`jax.jit` for JIT compilation to XLA, `jax.vmap` for automatic vectorization, `jax.pmap` for SPMD-style parallel programming), and execution on accelerators like GPUs and TPUs. JAX emphasizes pure functions, which means functions don't have side effects and always produce the same output for the same input.\n",
        "\n",
        "* **FLAX:** FLAX is a neural network library built on top of JAX, designed for flexibility and clarity.\n",
        "    * **FLAX NNX (`flax.nnx`):** NNX is an API within FLAX that aims to provide a more PyTorch-like, object-oriented programming model. Modules in NNX are stateful objects, meaning their parameters and other state (like BatchNorm statistics) are stored as attributes directly on the module instance. This can make model definition and state management feel more intuitive, especially when dealing with complex models or needing to access/modify parts of the model state (like we will for intermediate representations). It still seamlessly integrates with JAX's functional transformations.\n",
        "\n",
        "* **Optax:** Optax is a gradient processing and optimization library for JAX. It provides a wide range of popular optimizers (Adam, SGD, etc.) and makes it easy to build custom optimization schemes.\n",
        "\n",
        "Now, let's get our environment set up."
      ],
      "metadata": {
        "id": "MyTXOLVYvWCI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJp_piWfu_px"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries if not already present in your Colab environment\n",
        "# It's good practice to ensure you have recent versions.\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade jax # jaxlib\n",
        "!pip install --upgrade flax optax\n",
        "!pip install --upgrade tqdm\n",
        "!pip install tensorflow_datasets orbax-checkpoint matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax\n",
        "from flax import nnx\n",
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf # For tf.data pipelines\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial # For using partial functions\n",
        "import orbax.checkpoint as ocp # For saving and loading model checkpoints\n",
        "from typing import Sequence, Tuple, Dict, Any, Optional, Callable\n",
        "# Additional import for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Helper for managing PRNGKeys in JAX\n",
        "from jax import random\n",
        "\n",
        "import pathlib\n",
        "import shutil # For cleaning up directories if needed\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Check JAX device\n",
        "print(f\"JAX version: {jax.__version__}\")\n",
        "print(f\"FLAX version: {flax.__version__}\") # NNX is part of flax\n",
        "print(f\"Optax version: {optax.__version__}\")\n",
        "print(f\"Default JAX backend: {jax.default_backend()}\")\n",
        "print(f\"Available JAX devices: {jax.devices()}\")"
      ],
      "metadata": {
        "id": "ATILDFe_vdBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download all checkpoints and add utility to restore models"
      ],
      "metadata": {
        "id": "Xe2rHDHVMuLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_urls = [\n",
        " (\"student_model_final\", \"https://raw.githubusercontent.com/mridul-sahu/knowledge_distillation_intuitions/main/student_model_final.zip\"),\n",
        " (\"student_model_kd_final\", \"https://raw.githubusercontent.com/mridul-sahu/knowledge_distillation_intuitions/main/student_model_kd_final.zip\"),\n",
        " (\"teacher_model_final\", \"https://raw.githubusercontent.com/mridul-sahu/knowledge_distillation_intuitions/main/teacher_model_final.zip\")\n",
        "]\n",
        "checkpoint_dir = pathlib.Path('/tmp/flax_nnx_kd_checkpoints/')\n",
        "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for model_name, checkpoint_url in checkpoint_urls:\n",
        "  checkpoint_zip_path = checkpoint_dir / f\"{model_name}.zip\"\n",
        "  checkpoint_dir_sub = checkpoint_dir / model_name\n",
        "\n",
        "  # --- Download and Extract Checkpoints ---\n",
        "  if not checkpoint_dir_sub.exists():\n",
        "      if not checkpoint_zip_path.exists():\n",
        "          print(f\"Downloading checkpoints from {checkpoint_url}...\")\n",
        "          urllib.request.urlretrieve(checkpoint_url, checkpoint_zip_path)\n",
        "          print(f\"Checkpoints downloaded to {checkpoint_zip_path}\")\n",
        "      else:\n",
        "          print(f\"Checkpoints zip file already exists at {checkpoint_zip_path}\")\n",
        "\n",
        "      print(f\"Extracting {checkpoint_zip_path}...\")\n",
        "      with zipfile.ZipFile(checkpoint_zip_path, \"r\") as zip_ref:\n",
        "          zip_ref.extractall(\"/\") # zips have full path /tmp/flax_nnx_kd_checkpoints/{model_name}\n",
        "      print(f\"Checkpoints extracted to {checkpoint_dir_sub}\")\n",
        "  else:\n",
        "      print(f\"Checkpoints directory {checkpoint_dir} already exists. Skipping download and extraction.\")"
      ],
      "metadata": {
        "id": "fc2kPjLHKQRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp/flax_nnx_kd_checkpoints/"
      ],
      "metadata": {
        "id": "Cx6PhyL0QDhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_model(model: nnx.Module, model_name):\n",
        "  with ocp.StandardCheckpointer() as checkpointer:\n",
        "    model_ckpt_path = os.path.join(checkpoint_dir, model_name)\n",
        "    model_weights = checkpointer.restore(model_ckpt_path, nnx.state(model, nnx.Param))\n",
        "    nnx.update(model, model_weights)"
      ],
      "metadata": {
        "id": "9gdrpob0M2q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2. Global Configurations\n",
        "\n",
        "We can set some global configurations like batch size, learning rate, etc., here. These can be overridden later if needed for specific experiments."
      ],
      "metadata": {
        "id": "MggRDXfiwHdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global configurations\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001 # A common starting point for Adam\n",
        "NUM_EPOCHS_TEACHER = 30 # Teacher needs to learn well\n",
        "NUM_EPOCHS_STUDENT = 30 # Student also gets a fair number of epochs\n",
        "NUM_CLASSES = 10\n",
        "RNG_SEED = 42 # For reproducibility\n",
        "\n",
        "# For NNX, we often need to manage PRNG key sequences.\n",
        "# Let's create a main key and split it for different purposes.\n",
        "# This initial key will be used to derive more keys as needed.\n",
        "main_key = random.key(RNG_SEED)\n",
        "\n",
        "# CIFAR-10 mean and std for normalization\n",
        "# These values are commonly used for CIFAR-10 pre-trained models.\n",
        "CIFAR10_MEAN = jnp.array([0.49139968, 0.48215841, 0.44653091])\n",
        "CIFAR10_STD = jnp.array([0.24703223, 0.24348513, 0.26158784])\n",
        "# We'll stick with one set for consistency. Let's use the first one."
      ],
      "metadata": {
        "id": "mY4dj7hJv6Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Understanding Knowledge Distillation (A Quick Recap)\n",
        "\n",
        "Before diving into the code, let's briefly revisit the core idea of knowledge distillation.\n",
        "\n",
        "Imagine you have a very skilled teacher (a large, complex, and accurate neural network) and a student (a smaller, faster neural network). The student wants to learn to perform a task as well as the teacher.\n",
        "\n",
        "**How does the student learn?**\n",
        "\n",
        "1.  **Learning from the ground truth:** The student can learn directly from the actual labels in the training data (e.g., \"this image is a cat\"). This is the standard way of training.\n",
        "2.  **Learning from the teacher's \"wisdom\":** The teacher, having learned from vast amounts of data, often has a more nuanced understanding. For example, the teacher might say, \"I'm 90% sure this is a cat, but it also looks a tiny bit like a dog (5%), and definitely not like a car (0.01%).\" This full probability distribution over classes is called \"soft targets\" or \"soft labels.\"\n",
        "\n",
        "**Knowledge Distillation (KD)** is a technique where the student model is trained to do both:\n",
        "* Match the true labels (hard targets).\n",
        "* Mimic the soft targets produced by the pre-trained teacher model.\n",
        "\n",
        "**Why is this helpful?**\n",
        "\n",
        "* **Richer Information:** The soft targets from the teacher provide more information per training sample than just the hard labels. They reveal how the teacher model \"thinks\" and generalizes, including similarities between classes.\n",
        "* **Model Compression:** It allows us to \"distill\" the knowledge from a large, computationally expensive teacher model into a smaller, more efficient student model.\n",
        "* **Improved Performance:** The student often achieves better performance than if it were trained solely on hard labels, making it suitable for deployment on devices with limited computational resources (like mobile phones or embedded systems).\n",
        "\n",
        "In this tutorial, we'll explore a few ways to transfer this knowledge."
      ],
      "metadata": {
        "id": "tvs11Qvzwj10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Data Loading and Preprocessing (CIFAR-10)\n",
        "\n",
        "We'll use the CIFAR-10 dataset. It consists of 60,000 32x32 color images in 10 classes (50,000 training, 10,000 test). We'll use `tensorflow_datasets` (TFDS) and `tf.data` for efficient input pipelines."
      ],
      "metadata": {
        "id": "pv2IjrYDwvAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image, label, training: bool):\n",
        "    \"\"\"Converts image to float, normalizes to [0,1], applies augmentations (if training),\n",
        "       and then standard mean/std normalization.\n",
        "    \"\"\"\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32) # uint8 -> float32, scales to [0,1]\n",
        "\n",
        "    if training:\n",
        "        # Augmentations\n",
        "        # Random horizontal flip\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "        # Pad and random crop (CIFAR-10: 32x32 -> pad to 40x40 -> crop 32x32)\n",
        "        image_shape = tf.shape(image)\n",
        "        image_height, image_width = image_shape[0], image_shape[1]\n",
        "        padded_image = tf.image.resize_with_crop_or_pad(\n",
        "            image, image_height + 8, image_width + 8\n",
        "        )\n",
        "        image = tf.image.random_crop(padded_image, size=[image_height, image_width, 3])\n",
        "\n",
        "    # Standard mean/std normalization\n",
        "    image = (image - CIFAR10_MEAN) / CIFAR10_STD\n",
        "    return image, label\n",
        "\n",
        "def create_datasets(batch_size: int):\n",
        "    \"\"\"Creates training and test datasets for CIFAR-10.\"\"\"\n",
        "    # Load using TFDS\n",
        "    (train_ds_tf, test_ds_tf), ds_info = tfds.load('cifar10', split=['train', 'test'], as_supervised=True, with_info=True)\n",
        "\n",
        "    # Training dataset\n",
        "    train_preprocess_fn = partial(preprocess_image, training=True)\n",
        "    train_ds = train_ds_tf.map(train_preprocess_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    train_ds = train_ds.shuffle(ds_info.splits['train'].num_examples)\n",
        "    train_ds = train_ds.batch(batch_size)\n",
        "    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Test dataset\n",
        "    test_preprocess_fn = partial(preprocess_image, training=False) # No augmentation key needed\n",
        "    test_ds = test_ds_tf.map(test_preprocess_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    test_ds = test_ds.batch(batch_size)\n",
        "    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return tfds.as_numpy(train_ds), tfds.as_numpy(test_ds), ds_info"
      ],
      "metadata": {
        "id": "ry7yXIA7wQnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, test_ds, ds_info = create_datasets(BATCH_SIZE)\n",
        "\n",
        "# Inspect a batch\n",
        "sample_train_batch = next(iter(train_ds))\n",
        "images, labels = sample_train_batch\n",
        "print(\"Sample Training Batch:\")\n",
        "print(f\"  Images shape: {images.shape}, dtype: {images.dtype}\")\n",
        "print(f\"  Labels shape: {labels.shape}, dtype: {labels.dtype}\")\n",
        "print(f\"  Image min/max after full normalization: {images.min():.2f} / {images.max():.2f}\")\n",
        "\n",
        "\n",
        "# Optional: Display a few images\n",
        "def denormalize_for_display(image_batch_normalized):\n",
        "    # Reverse the mean/std normalization\n",
        "    return np.clip((image_batch_normalized * CIFAR10_STD) + CIFAR10_MEAN, 0, 1)\n",
        "\n",
        "images_to_show = denormalize_for_display(images[:4]) # Show fewer images\n",
        "\n",
        "plt.figure(figsize=(8, 2)) # Adjusted figure size\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.imshow(images_to_show[i])\n",
        "    plt.title(f\"Label: {labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Sample Training Images (Augmented & De-normalized for Display)\")\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.90])\n",
        "plt.show()\n",
        "\n",
        "num_train_examples = ds_info.splits['train'].num_examples\n",
        "num_test_examples = ds_info.splits['test'].num_examples\n",
        "steps_per_epoch_train = num_train_examples // BATCH_SIZE\n",
        "steps_per_epoch_test = num_test_examples // BATCH_SIZE\n",
        "\n",
        "print(f\"\\nNumber of training examples: {num_train_examples}\")\n",
        "print(f\"Number of test examples: {num_test_examples}\")\n",
        "print(f\"Training steps per epoch: {steps_per_epoch_train}\")\n",
        "print(f\"Test steps per epoch: {steps_per_epoch_test}\")"
      ],
      "metadata": {
        "id": "DtMmBAEExMQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Defining Model Architectures with FLAX NNX\n",
        "\n",
        "Now, we'll define our neural network architectures using FLAX NNX. NNX allows us to define modules in a more object-oriented way, where layers (and their parameters) are attributes of the module class.\n",
        "\n",
        "**Key NNX Concepts Used Here:**\n",
        "* `nnx.Module`: Base class for all NNX modules.\n",
        "* `nnx.Conv`: Convolutional layer.\n",
        "* `nnx.Linear`: Fully connected (dense) layer.\n",
        "* `nnx.Dropout`: Dropout layer for regularization.\n",
        "* `nnx.max_pool` (functional): Max pooling operation.\n",
        "* `nnx.Sequential`: A container for running a sequence of layers or functions.\n",
        "* `nnx.Rngs`: A way to manage JAX PRNGKeys for operations like dropout and parameter initialization within NNX modules.\n",
        "* `nnx.Param`: Wrapper to indicate that an attribute is a trainable parameter. NNX layers like `nnx.Linear` and `nnx.Conv` manage their `nnx.Param` attributes internally.\n",
        "* **Initialization**: In NNX, layers are typically instantiated in the `__init__` method, and they create their parameters at that time, given an appropriate `rngs` context for `'params'`.\n",
        "* **`__call__` method**: This is where the forward pass logic is defined.\n",
        "\n",
        "We'll create two CNNs:\n",
        "1.  `DeepNN_NNX`: A deeper network to serve as our teacher.\n",
        "2.  `LightNN_NNX`: A shallower, lightweight network for our student.\n",
        "\n",
        "The architectures will be similar to the PyTorch tutorial to facilitate comparison."
      ],
      "metadata": {
        "id": "gRFFMA5I3wbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nnx.Module):\n",
        "  \"\"\"A helper module for a common Conv -> ReLU -> Conv -> ReLU -> MaxPool sequence.\"\"\"\n",
        "  def __init__(self, in_filters1: int, out_filters1: int, out_filters2: int, *, rngs: nnx.Rngs):\n",
        "    self.conv1 = nnx.Conv(in_filters1, out_filters1, kernel_size=(3, 3), padding=1, rngs=rngs)\n",
        "    self.conv2 = nnx.Conv(out_filters1, out_filters2, kernel_size=(3, 3), padding=1, rngs=rngs)\n",
        "\n",
        "  def __call__(self, x: jax.Array) -> jax.Array:\n",
        "    x = nnx.relu(self.conv1(x))\n",
        "    x = nnx.relu(self.conv2(x))\n",
        "    x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
        "    return x\n",
        "\n",
        "class Classifier(nnx.Module):\n",
        "  \"\"\"A helper module for the classification head.\"\"\"\n",
        "  def __init__(self, in_features: int, hidden_features: int, out_features: int, dropout_rate: float, *, rngs: nnx.Rngs):\n",
        "    self.linear1 = nnx.Linear(in_features, hidden_features, rngs=rngs)\n",
        "    self.dropout = nnx.Dropout(rate=dropout_rate, rngs=rngs) # rngs for dropout state init\n",
        "    self.linear2 = nnx.Linear(hidden_features, out_features, rngs=rngs)\n",
        "\n",
        "  def __call__(self, x: jax.Array) -> jax.Array:\n",
        "    x = nnx.relu(self.linear1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear2(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class DeepNN_NNX(nnx.Module):\n",
        "  \"\"\"Deeper CNN for the teacher model.\"\"\"\n",
        "  def __init__(self, num_classes: int, *, rngs: nnx.Rngs):\n",
        "    # features will apply ConvBlocks sequentially\n",
        "    # Each ConvBlock handles its own convs, relus, and max_pool\n",
        "    self.features_block1 = ConvBlock(3, 128, 64, rngs=rngs)      # Output: 64 x 16 x 16\n",
        "    self.features_block2 = ConvBlock(64, 64, 32, rngs=rngs)       # Output: 32 x 8 x 8\n",
        "\n",
        "    # After two ConvBlocks, image size 32x32 -> 16x16 (after block1) -> 8x8 (after block2).\n",
        "    # So, flattened features = 32 * 8 * 8 = 2048\n",
        "    self.classifier = Classifier(32 * 8 * 8, 512, num_classes, dropout_rate=0.1, rngs=rngs)\n",
        "\n",
        "  def __call__(self, x: jax.Array) -> jax.Array:\n",
        "    x = self.features_block1(x)\n",
        "    x = self.features_block2(x)\n",
        "    x = x.reshape((x.shape[0], -1))  # Flatten\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class LightNN_NNX(nnx.Module):\n",
        "  \"\"\"Lightweight CNN for the student model.\"\"\"\n",
        "  def __init__(self, num_classes: int, *, rngs: nnx.Rngs):\n",
        "    self.conv1 = nnx.Conv(3, 16, kernel_size=(3,3), padding=1, rngs=rngs)\n",
        "    self.conv2 = nnx.Conv(16, 16, kernel_size=(3,3), padding=1, rngs=rngs)\n",
        "    # Pooling and relu are functional\n",
        "\n",
        "    # After feature extraction (2x Conv->ReLU->Pool), image size 32x32 -> 16x16 -> 8x8.\n",
        "    # Filters: 16. So, flattened features = 16 * 8 * 8 = 1024\n",
        "    self.classifier = Classifier(16 * 8 * 8, 256, num_classes, dropout_rate=0.1, rngs=rngs)\n",
        "\n",
        "  def __call__(self, x: jax.Array) -> jax.Array:\n",
        "    x = nnx.relu(self.conv1(x))\n",
        "    x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
        "    x = nnx.relu(self.conv2(x))\n",
        "    x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
        "    x = x.reshape((x.shape[0], -1))  # Flatten\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "kISw7hgbxUBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's initialize the models and test them with a dummy input\n",
        "# We need to provide appropriate RNGs for 'params' and 'dropout' (if used during call)\n",
        "\n",
        "# Derive keys for model initialization\n",
        "key_teacher_params, key_student_params, main_key = random.split(main_key, 3)\n",
        "\n",
        "# Create RNGs contexts for NNX\n",
        "# 'params' for parameter initialization\n",
        "# 'dropout' for dropout layers during forward pass if training\n",
        "# 'default' can be used if no specific key is needed by a layer for its init\n",
        "teacher_rngs = nnx.Rngs(params=key_teacher_params, dropout=random.key(1)) # new dropout key for teacher\n",
        "student_rngs = nnx.Rngs(params=key_student_params, dropout=random.key(2)) # new dropout key for student\n",
        "\n",
        "# Initialize Teacher Model\n",
        "teacher_model = DeepNN_NNX(num_classes=NUM_CLASSES, rngs=teacher_rngs)\n",
        "print(\"Teacher Model Initialized.\")\n",
        "\n",
        "# Initialize Student Model\n",
        "student_model = LightNN_NNX(num_classes=NUM_CLASSES, rngs=student_rngs)\n",
        "print(\"Student Model Initialized.\")\n",
        "\n",
        "# Create a dummy input batch (Batch, Height, Width, Channels)\n",
        "dummy_images = jnp.ones((BATCH_SIZE, 32, 32, 3))\n",
        "\n",
        "print(\"\\nTeacher Model Summary:\")\n",
        "print(nnx.tabulate(teacher_model, dummy_images))\n",
        "\n",
        "print(\"\\nStudent Model Summary:\")\n",
        "print(nnx.tabulate(student_model, dummy_images))"
      ],
      "metadata": {
        "id": "k20i8ABWzqAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Training Utilities in FLAX NNX\n",
        "\n",
        "With our models and data pipelines ready, we'll define the utilities for training and evaluation. We will closely follow the idiomatic patterns for Flax NNX, leveraging:\n",
        "\n",
        "* `nnx.Optimizer`: To bundle our model with an Optax optimizer, simplifying parameter updates and optimizer state management.\n",
        "* `nnx.jit`: For JIT-compiling our training and evaluation steps. It's NNX-aware and handles module state correctly.\n",
        "* `nnx.value_and_grad`: The NNX version for computing loss and gradients with respect to the model's `nnx.Param` variables.\n",
        "* `nnx.MultiMetric`: A convenient container for managing and computing multiple metrics like loss and accuracy.\n",
        "\n",
        "This approach makes the training code concise and leverages NNX's strengths."
      ],
      "metadata": {
        "id": "aYrZ9VQUCeBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Loss and Metrics Calculation Function ---\n",
        "def calculate_loss_and_logits(model: nnx.Module, batch: Tuple[jax.Array, jax.Array]):\n",
        "    \"\"\"\n",
        "    Calculates loss and logits for a given model and batch.\n",
        "    The `train` flag controls the behavior of layers like Dropout or BatchNorm.\n",
        "    \"\"\"\n",
        "    images, labels = batch # Assuming batch is a tuple (images, labels)\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=labels).mean()\n",
        "    return loss, logits\n",
        "\n",
        "# --- Train Step and Eval Step ---\n",
        "\n",
        "@nnx.jit\n",
        "def train_step(\n",
        "    model: nnx.Module,\n",
        "    optimizer: nnx.Optimizer,\n",
        "    metrics_computer: nnx.MultiMetric,\n",
        "    batch: Tuple[jax.Array, jax.Array]\n",
        "):\n",
        "    \"\"\"\n",
        "    Performs a single training step.\n",
        "    Updates model parameters, optimizer state, and metrics in-place.\n",
        "    \"\"\"\n",
        "    # Create a gradient function for calculate_loss_and_logits with respect to the model.\n",
        "    # has_aux=True is used because calculate_loss_and_logits returns (loss, logits).\n",
        "    grad_fn = nnx.value_and_grad(calculate_loss_and_logits, has_aux=True)\n",
        "\n",
        "    # Compute loss, logits, and gradients.\n",
        "    # State updates for layers happen here.\n",
        "    (loss, logits), grads = grad_fn(model, batch)\n",
        "\n",
        "    # Update metrics (e.g., loss, accuracy) in-place.\n",
        "    metrics_computer.update(loss=loss, logits=logits, labels=batch[1]) # batch[1] contains labels\n",
        "\n",
        "    # Apply gradients to update model parameters and optimizer state in-place.\n",
        "    optimizer.update(grads)\n",
        "\n",
        "\n",
        "@nnx.jit\n",
        "def eval_step(\n",
        "    model: nnx.Module,\n",
        "    metrics_computer: nnx.MultiMetric,\n",
        "    batch: Tuple[jax.Array, jax.Array]\n",
        "):\n",
        "    \"\"\"\n",
        "    Performs a single evaluation step.\n",
        "    Updates metrics in-place.\n",
        "    \"\"\"\n",
        "    # Compute loss and logits with the model in evaluation mode.\n",
        "    loss, logits = calculate_loss_and_logits(model, batch)\n",
        "\n",
        "    # Update metrics in-place.\n",
        "    metrics_computer.update(loss=loss, logits=logits, labels=batch[1])"
      ],
      "metadata": {
        "id": "-paPRra_6ebJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Workflow with `nnx.Optimizer` and `nnx.MultiMetric`:**\n",
        "\n",
        "1.  **Initialization:**\n",
        "    * An `nnx.Optimizer` is created by passing it an `nnx.Module` instance and an Optax optimizer definition (e.g., `optax.adam(learning_rate)`).\n",
        "    * An `nnx.MultiMetric` object is created to hold individual metrics like `nnx.metrics.Average` (for loss) and `nnx.metrics.Accuracy`.\n",
        "\n",
        "2.  **`train_step(model, optimizer, metrics_computer, batch)`:**\n",
        "    * The `model` argument here is typically `optimizer.module`.\n",
        "    * `nnx.value_and_grad` is used to get the loss, auxiliary outputs (logits), and gradients for `calculate_loss_and_logits`.\n",
        "    * `metrics_computer.update(...)` is called with the loss and logits to accumulate metric values for the current epoch/evaluation period. This updates the `metrics_computer` object in-place.\n",
        "    * `optimizer.update(grads)` applies the gradients using the wrapped Optax optimizer. This updates the parameters of `optimizer.module` and the Optax optimizer's internal state, all in-place.\n",
        "\n",
        "3.  **`eval_step(model, metrics_computer, batch)`:**\n",
        "    * Similar to `train_step` but without gradient computation or optimizer updates. It calls `calculate_loss_and_logits` with `eval` mode on.\n",
        "\n",
        "4.  **Main Loop:**\n",
        "    * At the end of each evaluation period (e.g., an epoch), `metrics_computer.compute()` is called to get the aggregated metric values.\n",
        "    * `metrics_computer.reset()` is then called to clear the accumulators for the next period.\n",
        "    * All stateful objects (`optimizer.module`, `optimizer` itself, and `metrics_computer`) are modified in-place by the JIT-compiled step functions due to NNX's handling of reference semantics within its lifted transforms."
      ],
      "metadata": {
        "id": "uzRiGa2XJRhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Training Loop ---\n",
        "def train_and_evaluate(\n",
        "    model_to_train: nnx.Module,\n",
        "    optax_optimizer: optax.GradientTransformation,\n",
        "    train_ds: Any,\n",
        "    test_ds: Any,\n",
        "    num_epochs: int,\n",
        "    steps_per_epoch_train: int,\n",
        "    steps_per_epoch_test: int,\n",
        "    eval_every_epochs: int = 1, # Evaluate after every 'eval_every_epochs'\n",
        "    model_name: str = \"Model\"\n",
        ") -> Tuple[nnx.Module, Dict[str, list]]:\n",
        "    \"\"\"\n",
        "    Trains and evaluates an NNX model.\n",
        "    Uses tqdm for progress bars and plots metrics at the end.\n",
        "    \"\"\"\n",
        "    optimizer = nnx.Optimizer(model_to_train, optax_optimizer)\n",
        "\n",
        "    train_metrics_computer = nnx.MultiMetric(\n",
        "        loss=nnx.metrics.Average(\"loss\"), # Explicitly name for clarity in dict keys\n",
        "        accuracy=nnx.metrics.Accuracy()\n",
        "    )\n",
        "    eval_metrics_computer = nnx.MultiMetric(\n",
        "        loss=nnx.metrics.Average(\"loss\"),\n",
        "        accuracy=nnx.metrics.Accuracy()\n",
        "    )\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_accuracy': [],\n",
        "        'test_loss': [], 'test_accuracy': []\n",
        "    }\n",
        "\n",
        "    print(f\"\\nStarting training for {model_name} for {num_epochs} epochs...\")\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=f\"Training {model_name}\"):\n",
        "        # --- Training Phase ---\n",
        "        model_to_train.train()\n",
        "        train_ds_iterator = iter(train_ds)\n",
        "        train_metrics_computer.reset()\n",
        "        for batch in tqdm(train_ds_iterator, total=steps_per_epoch_train, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "            # Ensure data is JAX array; TFDS usually yields NumPy.\n",
        "            batch_tuple = (jnp.asarray(batch[0]), jnp.asarray(batch[1]))\n",
        "            train_step(model_to_train, optimizer, train_metrics_computer, batch_tuple)\n",
        "\n",
        "        computed_train_metrics = train_metrics_computer.compute()\n",
        "        history['train_loss'].append(computed_train_metrics['loss'].item())\n",
        "        history['train_accuracy'].append(computed_train_metrics['accuracy'].item())\n",
        "\n",
        "        tqdm.write(f\"{model_name} - Epoch {epoch+1}/{num_epochs} Training: \"\n",
        "                   f\"Avg Loss: {computed_train_metrics['loss']:.4f}, \"\n",
        "                   f\"Avg Acc: {computed_train_metrics['accuracy']:.4f}\")\n",
        "\n",
        "        # --- Evaluation Phase ---\n",
        "        if (epoch + 1) % eval_every_epochs == 0 or (epoch + 1) == num_epochs:\n",
        "          model_to_train.eval()\n",
        "          test_ds_iterator = iter(test_ds)\n",
        "          eval_metrics_computer.reset()\n",
        "          for eval_batch in tqdm(test_ds_iterator, total=steps_per_epoch_test, desc=f\"Epoch {epoch+1} Evaluation\", leave=False):\n",
        "              eval_batch_tuple = (jnp.asarray(eval_batch[0]), jnp.asarray(eval_batch[1]))\n",
        "              eval_step(model_to_train, eval_metrics_computer, eval_batch_tuple)\n",
        "\n",
        "          computed_eval_metrics = eval_metrics_computer.compute()\n",
        "          history['test_loss'].append(computed_eval_metrics['loss'].item())\n",
        "          history['test_accuracy'].append(computed_eval_metrics['accuracy'].item())\n",
        "\n",
        "          tqdm.write(f\"{model_name} - Epoch {epoch+1}/{num_epochs} Evaluation: \"\n",
        "                      f\"Avg Loss: {computed_eval_metrics['loss']:.4f}, \"\n",
        "                      f\"Avg Acc: {computed_eval_metrics['accuracy']:.4f}\")\n",
        "        tqdm.write(\"-\" * 70)\n",
        "\n",
        "    print(f\"Training finished for {model_name}.\")\n",
        "\n",
        "    # --- Plotting Final Metrics ---\n",
        "    epochs_evaluated_train = list(range(1, num_epochs + 1))\n",
        "    # Test metrics might not be available for every epoch if eval_every_epochs > 1\n",
        "    epochs_evaluated_test = list(range(eval_every_epochs, num_epochs + eval_every_epochs, eval_every_epochs))\n",
        "    # Ensure the last epoch is included if it was an eval epoch\n",
        "    if num_epochs not in epochs_evaluated_test and (num_epochs % eval_every_epochs == 0 or num_epochs == num_epochs) :\n",
        "        if len(history['test_loss']) == len(epochs_evaluated_train) / eval_every_epochs : # a bit heuristic\n",
        "             pass # already covered\n",
        "        elif len(history['test_loss']) < len(epochs_evaluated_train) and len(history['test_loss']) > 0 : # if last epoch was eval but not caught by range\n",
        "             if epochs_evaluated_test[-1] != num_epochs : epochs_evaluated_test.append(num_epochs)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_evaluated_train, history['train_loss'], label='Train Loss', marker='o', linestyle='-')\n",
        "    if history['test_loss']: # Only plot if there's data\n",
        "        plt.plot(epochs_evaluated_test, history['test_loss'], label='Test Loss', marker='x', linestyle='--')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'{model_name} - Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_evaluated_train, history['train_accuracy'], label='Train Accuracy', marker='o', linestyle='-')\n",
        "    if history['test_accuracy']: # Only plot if there's data\n",
        "        plt.plot(epochs_evaluated_test, history['test_accuracy'], label='Test Accuracy', marker='x', linestyle='--')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'{model_name} - Accuracy Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return model_to_train, history"
      ],
      "metadata": {
        "id": "JRBFV3KxLOA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Experiment 1 - Baseline: Training Teacher and Student Independently\n",
        "\n",
        "Now that we have our model architectures (Part 3) and training utilities (Part 4) defined, we can start training our models.\n",
        "\n",
        "**Goals for this section:**\n",
        "1.  Train the `DeepNN_NNX` (Teacher) model from scratch on CIFAR-10 and record its performance.\n",
        "2.  Train the `LightNN_NNX` (Student) model from scratch on CIFAR-10, also independently, and record its performance. This will serve as our baseline student accuracy.\n",
        "\n",
        "We will use the `train_and_evaluate` function we defined earlier. For reproducibility, and to ensure fair comparisons later (e.g., when training the student with distillation vs. without), we need to be careful with our JAX PRNGKeys for model initialization.\n",
        "\n",
        "**Checkpointing:**\n",
        "We'll also include a basic setup for saving and loading model weights using Orbax, which is the recommended checkpointing library for JAX/Flax."
      ],
      "metadata": {
        "id": "Nw2hWXkq0Ad2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Train the Teacher Model (DeepNN_NNX) ---\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"Training Teacher Model (DeepNN_NNX)\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# Define Optax optimizer for the teacher\n",
        "teacher_optimizer = optax.adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "restored = False\n",
        "try:\n",
        "  restore_model(teacher_model, \"teacher_model_final\")\n",
        "  trained_teacher_model = teacher_model\n",
        "  restored = True\n",
        "except Exception as e:\n",
        "  print(f\"Restore failed: {e}\")\n",
        "  restored=False\n",
        "\n",
        "if not restored:\n",
        "  trained_teacher_model, teacher_history = train_and_evaluate(\n",
        "      model_to_train=teacher_model, # Pass the instantiated model\n",
        "      optax_optimizer=teacher_optimizer,\n",
        "      train_ds=train_ds,\n",
        "      test_ds=test_ds,\n",
        "      num_epochs=NUM_EPOCHS_TEACHER,\n",
        "      steps_per_epoch_train=steps_per_epoch_train,\n",
        "      steps_per_epoch_test=steps_per_epoch_test,\n",
        "      model_name=\"Teacher (DeepNN)\"\n",
        "  )"
      ],
      "metadata": {
        "id": "dkXi92cvLfQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  teacher_model_save_path = os.path.join(checkpoint_dir, \"teacher_model_final\")\n",
        "  ocp.StandardCheckpointer().save(teacher_model_save_path, nnx.state(trained_teacher_model, nnx.Param))\n",
        "  print(f\"Teacher model parameters saved to {teacher_model_save_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Could not save teacher model: {e}\")"
      ],
      "metadata": {
        "id": "mWl94orC2uAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /tmp/flax_nnx_kd_checkpoints/teacher_model_final.zip /tmp/flax_nnx_kd_checkpoints/teacher_model_final\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/tmp/flax_nnx_kd_checkpoints/teacher_model_final.zip\")"
      ],
      "metadata": {
        "id": "DLhDZ4AE7hL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Train the Baseline Student Model (LightNN_NNX) ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"Training Baseline Student Model (LightNN_NNX)\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# Define Optax optimizer for the student\n",
        "student_optimizer = optax.adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "restored = False\n",
        "try:\n",
        "  restore_model(student_model, \"student_model_final\")\n",
        "  trained_student_model = student_model\n",
        "  restored = True\n",
        "except Exception as e:\n",
        "  print(f\"Restore failed: {e}\")\n",
        "  restored=False\n",
        "\n",
        "if not restored:\n",
        "  trained_student_model, student_history = train_and_evaluate(\n",
        "      model_to_train=student_model, # Pass the instantiated model\n",
        "      optax_optimizer=student_optimizer,\n",
        "      train_ds=train_ds,\n",
        "      test_ds=test_ds,\n",
        "      num_epochs=NUM_EPOCHS_STUDENT,\n",
        "      steps_per_epoch_train=steps_per_epoch_train,\n",
        "      steps_per_epoch_test=steps_per_epoch_test,\n",
        "      model_name=\"Student (DeepNN)\"\n",
        "  )"
      ],
      "metadata": {
        "id": "XL_rXsY17wSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  student_model_save_path = os.path.join(checkpoint_dir, \"student_model_final\")\n",
        "  ocp.StandardCheckpointer().save(student_model_save_path, nnx.state(trained_student_model, nnx.Param))\n",
        "  print(f\"Student model parameters saved to {student_model_save_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Could not save student model: {e}\")"
      ],
      "metadata": {
        "id": "V3GWvMQc8S3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /tmp/flax_nnx_kd_checkpoints/student_model_final.zip /tmp/flax_nnx_kd_checkpoints/student_model_final\n",
        "\n",
        "files.download(\"/tmp/flax_nnx_kd_checkpoints/student_model_final.zip\")"
      ],
      "metadata": {
        "id": "Pi1LY7m_8Zm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Performance Summary\n",
        "\n",
        "After training both models independently, we have:\n",
        "\n",
        "* **Teacher Model (DeepNN_NNX) Final Test Accuracy:** We'll fill this in after running the cell above.\n",
        "* **Baseline Student Model (LightNN_NNX) Final Test Accuracy:** We'll fill this in after running the cell above.\n",
        "\n",
        "The goal of knowledge distillation will be to train a *new instance* of the `LightNN_NNX` (initialized with the *same* starting parameters as this baseline student for a fair comparison) to achieve an accuracy closer to the teacher's, or ideally even surpass this baseline student's performance, without changing the student model's architecture."
      ],
      "metadata": {
        "id": "I-VyJEzA-DZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Experiment 2 - Standard Knowledge Distillation (Matching Output Logits)\n",
        "\n",
        "Now that we have baseline performances for our teacher and student models, we'll implement the classic knowledge distillation technique, often attributed to Hinton et al. (2015).\n",
        "\n",
        "**The Core Idea:**\n",
        "\n",
        "The student model learns by minimizing a combined loss function:\n",
        "1.  **Standard Cross-Entropy Loss:** Calculated between the student's predictions and the true labels (hard targets). This ensures the student still learns the primary task correctly.\n",
        "2.  **Distillation Loss (Soft Target Loss):** Calculated between the student's predictions and the \"soft targets\" provided by the pre-trained teacher model.\n",
        "\n",
        "**Soft Targets and Temperature:**\n",
        "\n",
        "* **Teacher's Knowledge:** A well-trained teacher model, even when it makes a wrong prediction, often assigns higher probabilities to classes that are semantically similar to the true class. For example, it might confuse a \"truck\" with an \"automobile\" but is unlikely to confuse it with a \"dog\". This rich similarity information is present in the teacher's full output probability distribution (logits).\n",
        "* **Softening Probabilities:** To make this nuanced information more accessible to the student (especially the smaller probabilities for non-target classes), we use a \"temperature\" hyperparameter ($T$).\n",
        "    * The logits of both the teacher and the student are divided by $T$ before applying the softmax function: $p_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$, where $z_i$ are the logits.\n",
        "    * A higher $T > 1$ \"softens\" the probability distribution, making it less peaky (i.e., probabilities become more uniform). This amplifies the contribution of smaller logit values, allowing the student to learn from the relative similarities the teacher has learned.\n",
        "    * When $T=1$, it's the standard softmax.\n",
        "* **Distillation Loss Calculation:** The distillation loss typically measures the difference between the student's softened probabilities and the teacher's softened probabilities. A common choice is the Kullback-Leibler (KL) divergence or a cross-entropy loss between these softened distributions. The original paper by Hinton et al. also suggests scaling this part of the loss by $T^2$.\n",
        "\n",
        "**Combined Loss Function:**\n",
        "The total loss for the student is a weighted sum:\n",
        "$L_{total} = w_{CE} \\cdot L_{CE}(\\text{student_preds, true_labels}) + w_{KD} \\cdot L_{KD}(\\text{student_soft_preds, teacher_soft_preds}, T)$\n",
        "where $w_{CE}$ and $w_{KD}$ are weights that balance the two loss components.\n",
        "\n",
        "In this experiment, we will:\n",
        "1.  Initialize a new student model instance **with the exact same initial parameters** as our baseline student for a fair comparison.\n",
        "2.  Use our already trained `trained_teacher_model` (in evaluation mode) to provide soft targets.\n",
        "3.  Define a new training step that incorporates this combined loss.\n",
        "4.  Train the student and compare its performance against the baseline student.\n"
      ],
      "metadata": {
        "id": "mX_E2fEI_U8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Knowledge Distillation Specific Functions ---\n",
        "\n",
        "def distillation_loss_calculation(\n",
        "    student_logits: jax.Array,\n",
        "    teacher_logits: jax.Array, # Teacher logits should be from teacher in eval mode\n",
        "    temperature: float\n",
        ") -> jax.Array:\n",
        "    \"\"\"\n",
        "    Calculates the knowledge distillation loss.\n",
        "    Uses cross-entropy between softened teacher predictions and softened student predictions.\n",
        "    \"\"\"\n",
        "    # Soften probabilities with temperature\n",
        "    # Teacher provides soft targets (probabilities)\n",
        "    soft_teacher_targets = jax.nn.softmax(teacher_logits / temperature, axis=-1)\n",
        "\n",
        "    # Student's output (log probabilities for numerical stability with cross-entropy)\n",
        "    log_soft_student_probs = jax.nn.log_softmax(student_logits / temperature, axis=-1)\n",
        "\n",
        "    # Distillation loss: Cross-entropy between teacher's soft targets and student's soft log-probabilities\n",
        "    # This is equivalent to minimizing KL divergence KL(P_teacher_soft || P_student_soft)\n",
        "    # when the P_teacher_soft part of KL divergence is considered constant wrt student params.\n",
        "    kd_loss = -jnp.sum(soft_teacher_targets * log_soft_student_probs, axis=-1).mean()\n",
        "\n",
        "    # Scale by T^2 as suggested in Hinton et al. (2015)\n",
        "    # This scaling ensures that the relative contribution of the distillation loss\n",
        "    # is maintained as temperature changes the scale of the logits.\n",
        "    return kd_loss * (temperature**2)\n",
        "\n",
        "\n",
        "def combined_loss_and_logits_for_distillation(\n",
        "    student_model_for_grad: nnx.Module, # The student model instance being differentiated\n",
        "    teacher_model_eval: nnx.Module,     # The pre-trained teacher model (used in eval mode)\n",
        "    batch: Tuple[jax.Array, jax.Array],\n",
        "    temperature: float,\n",
        "    ce_student_weight: float, # Weight for the student's cross-entropy loss with true labels\n",
        "    kd_loss_weight: float,    # Weight for the distillation loss\n",
        "):\n",
        "    \"\"\"\n",
        "    Calculates the combined loss (CE + KD) and student logits.\n",
        "    This function will be differentiated w.r.t. student_model_for_grad.\n",
        "    \"\"\"\n",
        "    images, true_labels = batch\n",
        "\n",
        "    # 1. Forward pass for student\n",
        "    student_logits = student_model_for_grad(images)\n",
        "\n",
        "    # 2. Standard Cross-Entropy loss for student with true labels\n",
        "    ce_loss = optax.softmax_cross_entropy_with_integer_labels(\n",
        "        logits=student_logits, labels=true_labels\n",
        "    ).mean()\n",
        "\n",
        "    # 3. Forward pass for teacher (in evaluation mode, no gradients for teacher)\n",
        "    # Ensure teacher_model_eval is not updated by JAX's autodiff by not including its\n",
        "    # parameters in the differentiation target. NNX handles this if teacher_model_eval\n",
        "    # is just a regular argument and not the one specified for `nnx.value_and_grad`.\n",
        "    teacher_logits_eval = teacher_model_eval(images) # Teacher always in eval mode\n",
        "\n",
        "    # 4. Knowledge Distillation loss\n",
        "    kd_loss = distillation_loss_calculation(student_logits, teacher_logits_eval, temperature)\n",
        "\n",
        "    # 5. Combined loss\n",
        "    total_loss = (ce_student_weight * ce_loss) + (kd_loss_weight * kd_loss)\n",
        "\n",
        "    return total_loss, student_logits # Return student_logits for accuracy calculation\n",
        "\n",
        "\n",
        "@nnx.jit\n",
        "def train_step_distillation(\n",
        "    student_model: nnx.Module,        # This is optimizer_student_kd.module\n",
        "    optimizer_student_kd: nnx.Optimizer,\n",
        "    teacher_model_eval: nnx.Module,   # Pre-trained teacher model\n",
        "    metrics_aggregator: nnx.MultiMetric,\n",
        "    batch: Tuple[jax.Array, jax.Array],\n",
        "    temperature: float,\n",
        "    ce_student_weight: float,\n",
        "    kd_loss_weight: float\n",
        "):\n",
        "    \"\"\"\n",
        "    Performs a single training step with knowledge distillation.\n",
        "    \"\"\"\n",
        "    # Define the function to be differentiated.\n",
        "    # It needs to take student_model as its first argument for nnx.value_and_grad.\n",
        "    # Other arguments (teacher, batch, T, weights) are \"closed over\" or passed as static args.\n",
        "    # For nnx.value_and_grad, if we differentiate w.r.t. student_model,\n",
        "    # other nnx.Module arguments like teacher_model_eval should be treated as static if they are not\n",
        "    # part of the differentiation target.\n",
        "\n",
        "    def loss_fn_wrapper(model_to_diff): # model_to_diff will be student_model\n",
        "        return combined_loss_and_logits_for_distillation(\n",
        "            model_to_diff, # Student model (target of differentiation)\n",
        "            teacher_model_eval,\n",
        "            batch,\n",
        "            temperature,\n",
        "            ce_student_weight,\n",
        "            kd_loss_weight,\n",
        "        )\n",
        "\n",
        "    grad_fn = nnx.value_and_grad(loss_fn_wrapper, has_aux=True)\n",
        "\n",
        "    # Execute grad_fn. student_model is updated here.\n",
        "    (loss, student_logits_for_metric), grads = grad_fn(student_model)\n",
        "\n",
        "    metrics_aggregator.update(loss=loss, logits=student_logits_for_metric, labels=batch[1])\n",
        "    optimizer_student_kd.update(grads) # Updates student_model in-place\n",
        "\n",
        "# Note: The eval_step remains the same as before, as it only evaluates the student.\n",
        "# We will reuse the `eval_step` defined in Part 4."
      ],
      "metadata": {
        "id": "bt3nwjs591CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup for Knowledge Distillation Training ---\n",
        "# The main training loop `train_and_evaluate` needs to be adapted or a new one created\n",
        "# to handle the specific arguments of `train_step_distillation`.\n",
        "# Let's create a new specific training loop for distillation for clarity.\n",
        "\n",
        "def train_and_evaluate_distillation(\n",
        "    student_model_to_train: nnx.Module,\n",
        "    teacher_model_for_guidance: nnx.Module,\n",
        "    optax_optimizer: optax.GradientTransformation,\n",
        "    train_ds: Any,\n",
        "    test_ds: Any,\n",
        "    num_epochs: int,\n",
        "    steps_per_epoch_train: int,\n",
        "    steps_per_epoch_test: int,\n",
        "    temperature: float,\n",
        "    ce_weight: float,\n",
        "    kd_weight: float,\n",
        "    eval_every_epochs: int = 1,\n",
        "    model_name: str = \"Student_KD\"\n",
        ") -> Tuple[nnx.Module, Dict[str, list]]:\n",
        "\n",
        "    optimizer = nnx.Optimizer(student_model_to_train, optax_optimizer)\n",
        "\n",
        "    train_metrics_aggregator = nnx.MultiMetric(\n",
        "        loss=nnx.metrics.Average(\"loss\"),\n",
        "        accuracy=nnx.metrics.Accuracy()\n",
        "    )\n",
        "    eval_metrics_aggregator = nnx.MultiMetric( # For student's performance on true labels\n",
        "        loss=nnx.metrics.Average(\"loss\"),\n",
        "        accuracy=nnx.metrics.Accuracy()\n",
        "    )\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_accuracy': [],\n",
        "        'test_loss': [], 'test_accuracy': []\n",
        "    }\n",
        "\n",
        "    total_training_steps = num_epochs * steps_per_epoch_train\n",
        "    print(f\"\\nStarting distillation training for {model_name} for {num_epochs} epochs...\")\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=f\"Training {model_name}\"):\n",
        "        student_model_to_train.train()\n",
        "        teacher_model_for_guidance.eval()\n",
        "        train_metrics_aggregator.reset()\n",
        "        train_epoch_bar = tqdm(iter(train_ds), total=steps_per_epoch_train,\n",
        "                               desc=f\"Epoch {epoch+1}/{num_epochs} [Distill Train]\",\n",
        "                               leave=False)\n",
        "        for batch in train_epoch_bar:\n",
        "            batch_images, batch_labels = batch\n",
        "            batch_tuple = (jnp.asarray(batch_images), jnp.asarray(batch_labels))\n",
        "\n",
        "            train_step_distillation(\n",
        "                student_model_to_train,\n",
        "                optimizer,\n",
        "                teacher_model_for_guidance,\n",
        "                train_metrics_aggregator,\n",
        "                batch_tuple,\n",
        "                temperature,\n",
        "                ce_weight,\n",
        "                kd_weight\n",
        "            )\n",
        "\n",
        "        computed_train_metrics = train_metrics_aggregator.compute()\n",
        "        history['train_loss'].append(computed_train_metrics['loss'].item())\n",
        "        history['train_accuracy'].append(computed_train_metrics['accuracy'].item())\n",
        "        tqdm.write(f\"{model_name} - Epoch {epoch+1} Training: Avg Loss: {computed_train_metrics['loss']:.4f}, Avg Acc: {computed_train_metrics['accuracy']:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % eval_every_epochs == 0 or (epoch + 1) == num_epochs:\n",
        "            student_model_to_train.eval()\n",
        "            eval_metrics_aggregator.reset()\n",
        "            eval_epoch_bar = tqdm(iter(test_ds), total=steps_per_epoch_test,\n",
        "                                  desc=f\"Epoch {epoch+1}/{num_epochs} [Distill Eval]\",\n",
        "                                  leave=False)\n",
        "            for eval_batch in eval_epoch_bar:\n",
        "                eval_batch_images, eval_batch_labels = eval_batch\n",
        "                eval_batch_tuple = (jnp.asarray(eval_batch_images), jnp.asarray(eval_batch_labels))\n",
        "                # Evaluate the student model using the standard eval_step\n",
        "                eval_step(student_model_to_train, eval_metrics_aggregator, eval_batch_tuple)\n",
        "\n",
        "            computed_eval_metrics = eval_metrics_aggregator.compute()\n",
        "            history['test_loss'].append(computed_eval_metrics['loss'].item())\n",
        "            history['test_accuracy'].append(computed_eval_metrics['accuracy'].item())\n",
        "            tqdm.write(f\"{model_name} - Epoch {epoch+1} Evaluation: Avg Loss: {computed_eval_metrics['loss']:.4f}, Avg Acc: {computed_eval_metrics['accuracy']:.4f}\")\n",
        "        tqdm.write(\"-\" * 70)\n",
        "\n",
        "    print(f\"Distillation training finished for {model_name}.\")\n",
        "\n",
        "    # Plotting (same as before)\n",
        "    evaluated_test_epochs = [e + 1 for e in range(num_epochs) if (e + 1) % eval_every_epochs == 0 or (e + 1) == num_epochs]\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), history['train_loss'], label='Train Loss', marker='o')\n",
        "    if history['test_loss']:\n",
        "        plt.plot(evaluated_test_epochs, history['test_loss'], label='Test Loss', marker='x', linestyle='--')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'{model_name}: Loss'); plt.legend(); plt.grid(True)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, num_epochs + 1), history['train_accuracy'], label='Train Accuracy', marker='o')\n",
        "    if history['test_accuracy']:\n",
        "        plt.plot(evaluated_test_epochs, history['test_accuracy'], label='Test Accuracy', marker='x', linestyle='--')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title(f'{model_name}: Accuracy'); plt.legend(); plt.grid(True)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    return student_model_to_train, history\n",
        "\n"
      ],
      "metadata": {
        "id": "DS6s09WxBnP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"Preparing for Knowledge Distillation Training\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "student_model_kd = LightNN_NNX(num_classes=NUM_CLASSES, rngs=student_rngs)\n",
        "print(\"Student model for distillation initialized with the same initial parameters as baseline student.\")\n",
        "\n",
        "# 3. Define hyperparameters for distillation\n",
        "TEMPERATURE = 2.0  # Common value, can be tuned\n",
        "CE_STUDENT_WEIGHT = 0.25 # Weight for the student's own CE loss on true labels\n",
        "KD_LOSS_WEIGHT = 0.75    # Weight for the distillation loss from teacher\n",
        "\n",
        "# 4. Create an optimizer for this new student model\n",
        "student_kd_optimizer = optax.adam(learning_rate=LEARNING_RATE) # Can be same or different LR\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"Training Student Model with Knowledge Distillation\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "restored = False\n",
        "try:\n",
        "  restore_model(student_model_kd, \"student_model_kd_final\")\n",
        "  trained_student_model_kd = student_model_kd\n",
        "  restored = True\n",
        "except Exception as e:\n",
        "  print(f\"Restore failed: {e}\")\n",
        "  restored=False\n",
        "\n",
        "if not restored:\n",
        "  trained_student_model_kd, student_kd_history = train_and_evaluate_distillation(\n",
        "      student_model_to_train=student_model_kd, # The re-initialized student\n",
        "      teacher_model_for_guidance=trained_teacher_model, # From Part 5\n",
        "      optax_optimizer=student_kd_optimizer,\n",
        "      train_ds=train_ds,\n",
        "      test_ds=test_ds,\n",
        "      num_epochs=NUM_EPOCHS_STUDENT, # Same number of epochs as baseline student\n",
        "      steps_per_epoch_train=steps_per_epoch_train,\n",
        "      steps_per_epoch_test=steps_per_epoch_test,\n",
        "      temperature=TEMPERATURE,\n",
        "      ce_weight=CE_STUDENT_WEIGHT,\n",
        "      kd_weight=KD_LOSS_WEIGHT,\n",
        "      model_name=\"Student_KD (LightNN + Distill)\"\n",
        "  )"
      ],
      "metadata": {
        "id": "rRr91QACDK89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  student_model_kd_save_path = os.path.join(checkpoint_dir, \"student_model_kd_final\")\n",
        "  ocp.StandardCheckpointer().save(student_model_kd_save_path, nnx.state(trained_student_model_kd, nnx.Param))\n",
        "  print(f\"Student model parameters saved to {student_model_kd_save_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Could not save student model kd: {e}\")"
      ],
      "metadata": {
        "id": "u2qmOwPmDkPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /tmp/flax_nnx_kd_checkpoints/student_model_kd_final.zip /tmp/flax_nnx_kd_checkpoints/student_model_kd_final\n",
        "\n",
        "files.download(\"/tmp/flax_nnx_kd_checkpoints/student_model_kd_final.zip\")"
      ],
      "metadata": {
        "id": "YKfXnWEYGbsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_model_accuracies(models: Dict[str, nnx.Module], test_ds: Any) -> Dict[str, float]:\n",
        "  output = {}\n",
        "  for model_name, model in models.items():\n",
        "    eval_metrics_aggregator = nnx.MultiMetric( # For student's performance on true labels\n",
        "          accuracy=nnx.metrics.Accuracy()\n",
        "    )\n",
        "    model.eval()\n",
        "    eval_metrics_aggregator.reset()\n",
        "    for eval_batch in tqdm(iter(test_ds), total=steps_per_epoch_test, desc=f\"Eval for {model_name}\", leave=False):\n",
        "      eval_batch_images, eval_batch_labels = eval_batch\n",
        "      eval_batch_tuple = (jnp.asarray(eval_batch_images), jnp.asarray(eval_batch_labels))\n",
        "      # Evaluate the student model using the standard eval_step\n",
        "      eval_step(model, eval_metrics_aggregator, eval_batch_tuple)\n",
        "\n",
        "    computed_eval_metrics = eval_metrics_aggregator.compute()\n",
        "    output[model_name] = computed_eval_metrics['accuracy'].item()\n",
        "    tqdm.write(f\"{model_name} Evaluation: Avg Acc: {computed_eval_metrics['accuracy']:.4f}\")\n",
        "  return output"
      ],
      "metadata": {
        "id": "LJCBoipmQdkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store results for final comparison table\n",
        "baseline_accuracies = compare_model_accuracies({\n",
        "    \"Teacher\": teacher_model,\n",
        "    \"Student_Baseline\": student_model,\n",
        "    \"Student_KD (Output Logits)\": student_model_kd\n",
        "}, test_ds)\n",
        "\n",
        "print(\"\\n--- Accuracy Summary So Far ---\")\n",
        "for model_name, acc in baseline_accuracies.items():\n",
        "    if isinstance(acc, str):\n",
        "        print(f\"{model_name}: {acc}\")\n",
        "    else:\n",
        "        print(f\"{model_name}: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "11HUkcIPGlmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7: Experiment 3 - Distilling from Intermediate Representations\n",
        "\n",
        "Previously, we performed knowledge distillation by matching the student's final output (logits) to the teacher's. Now, we'll explore a more nuanced approach: distilling knowledge from the **intermediate feature representations** learned within the teacher model.\n",
        "\n",
        "**Why Distill from Intermediate Layers?**\n",
        "\n",
        "* **Richer Supervisory Signals:** Intermediate layers of a well-trained teacher often capture complex data invariances and semantic information. Guiding the student to mimic these internal representations can provide a more potent learning signal.\n",
        "* **Hint-Based Learning:** This is akin to the teacher providing \"hints\" (as in FitNets by Romero et al., 2014) to the student about how to form its own internal features, rather than just matching the final answer.\n",
        "* **Bridging Capacity Gaps:** For a student with significantly less capacity than the teacher, directly matching the teacher's final output might be too challenging. Learning from intermediate \"stepping stones\" can be more effective.\n",
        "\n",
        "**Capturing Intermediates in NNX with `self.sow()`**\n",
        "\n",
        "Flax NNX provides a mechanism to \"sow\" or record intermediate values during the forward pass of a module. We can use `self.sow(VariableType, name, value)` within a module's `__call__` method.\n",
        "* `self.sow(nnx.Intermediate, 'my_feature_map', features_to_capture)`: This call will associate the `features_to_capture` with an `nnx.Intermediate` variable named `my_feature_map`.\n",
        "* After a forward pass, this \"sown\" variable (which becomes an attribute of the model instance if it's the first time `sow` is called with that name for that type) can be accessed, e.g., `model.my_feature_map.value`.\n",
        "* Alternatively, all intermediates of a certain type can be retrieved using `nnx.state(model, nnx.Intermediate)`.\n",
        "\n",
        "**Our Approach:**\n",
        "1.  Modify our `DeepNN_NNX` and `LightNN_NNX` base classes by creating subclasses that use `self.sow()` in their `__call__` methods to capture the feature maps produced right before the classifier.\n",
        "2.  Implement distillation techniques that use these captured intermediate features.\n"
      ],
      "metadata": {
        "id": "gU81cHOxamwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedDeep(DeepNN_NNX):\n",
        "  \"\"\"Deeper CNN for the teacher model with feature capture.\"\"\"\n",
        "\n",
        "  def __call__(self, x: jax.Array) -> jax.Array:\n",
        "    x = self.features_block1(x)\n",
        "    x = self.features_block2(x)\n",
        "    self.sow(nnx.Intermediate, 'deep_feature_map', x) # Capture Feature Map in self.deep_feature_map\n",
        "    x = x.reshape((x.shape[0], -1))  # Flatten\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class ModifiedLight(LightNN_NNX):\n",
        "  \"\"\"Lightweight CNN for the student model.\"\"\"\n",
        "\n",
        "  def __call__(self, x: jax.Array) -> jax.Array:\n",
        "    x = nnx.relu(self.conv1(x))\n",
        "    x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
        "    x = nnx.relu(self.conv2(x))\n",
        "    x = nnx.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='VALID')\n",
        "    self.sow(nnx.Intermediate, 'light_feature_map', x) # Capture Feature Map in self.light_feature_map\n",
        "    x = x.reshape((x.shape[0], -1))  # Flatten\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "6gdVfrv_SfUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Teacher Modified Model\n",
        "teacher_model_cosine_pt = ModifiedDeep(num_classes=NUM_CLASSES, rngs=teacher_rngs)\n",
        "print(\"Teacher Model Modified Initialized.\")\n",
        "\n",
        "# Initialize Student Modified Model\n",
        "student_model_cosine_pt = ModifiedLight(num_classes=NUM_CLASSES, rngs=student_rngs)\n",
        "print(\"Student Model Modified Initialized.\")\n",
        "\n",
        "print(\"\\nTeacher Model Modified Summary:\")\n",
        "print(nnx.tabulate(teacher_model_cosine_pt, dummy_images))\n",
        "\n",
        "print(\"\\nStudent Model Modified Summary:\")\n",
        "print(nnx.tabulate(student_model_cosine_pt, dummy_images))"
      ],
      "metadata": {
        "id": "BS-0rnIlWXP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 8: Experiment 3a - Cosine Loss on Hidden States (Teacher Feature Pooling)\n",
        "\n",
        "In this first variant of intermediate feature distillation, we aim to make the student's internal feature representations similar to a downsampled version of the teacher's. We will use **cosine similarity** as the metric.\n",
        "\n",
        "**Key Steps:**\n",
        "\n",
        "1.  **Feature Extraction (via `self.sow`)**:\n",
        "    * The **teacher model** (`ModifiedDeep`) provides its intermediate feature map (e.g., `deep_feature_map`).\n",
        "    * The **student model** (`ModifiedLight`) provides its intermediate feature map (e.g., `light_feature_map`).\n",
        "\n",
        "2.  **Dimensionality Matching (Teacher Pooling)**:\n",
        "    * The teacher's feature map (e.g., `B, 8, 8, 32` -> flattened to `B, 2048`) has a higher dimensionality than the student's (e.g., `B, 8, 8, 16` -> flattened to `B, 1024`).\n",
        "    * To match dimensions for the cosine loss, we will **flatten both feature maps** and then apply **1D average pooling to the teacher's flattened feature vector** to reduce its dimensionality to match the student's. This pooling will be done *within the loss function itself*, not by modifying the teacher model's architecture.\n",
        "\n",
        "3.  **Loss Calculation:**\n",
        "    * **Cosine Similarity Loss:** Calculated between the student's flattened features and the teacher's *pooled and flattened* features.\n",
        "    * **Cross-Entropy Loss:** The standard classification loss on the student's final output and the true labels.\n",
        "    * The total loss will be a weighted sum of these two."
      ],
      "metadata": {
        "id": "aB_mDiqZbPyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cosine Similarity Loss Function ---\n",
        "def cosine_similarity_loss_fn(x1: jax.Array, x2: jax.Array, epsilon: float = 1e-8) -> jax.Array:\n",
        "  \"\"\"\n",
        "  Computes 1 - cosine_similarity between two batches of vectors (mean over batch).\n",
        "  x1, x2 are expected to be 2D arrays (batch_size, num_features).\n",
        "  \"\"\"\n",
        "  x1_norm = x1 / (jnp.linalg.norm(x1, axis=-1, keepdims=True) + epsilon)\n",
        "  x2_norm = x2 / (jnp.linalg.norm(x2, axis=-1, keepdims=True) + epsilon)\n",
        "  similarity = jnp.sum(x1_norm * x2_norm, axis=-1)\n",
        "  return jnp.mean(1.0 - similarity)\n",
        "\n",
        "\n",
        "# --- Combined Loss Function for Cosine Distillation (Teacher Pooling) ---\n",
        "def combined_loss_logits_features_cosine_pooled_teacher(\n",
        "    student_model: ModifiedLight,   # Student model (sows its features)\n",
        "    teacher_model: ModifiedDeep,    # Teacher model (sows its features)\n",
        "    batch: Tuple[jax.Array, jax.Array],\n",
        "    ce_student_weight: float,\n",
        "    cosine_loss_weight: float\n",
        "):\n",
        "    \"\"\"\n",
        "    Calculates combined loss (CE + Cosine Sim with teacher feature pooling)\n",
        "    and returns student logits.\n",
        "    \"\"\"\n",
        "    images, true_labels = batch\n",
        "\n",
        "    # 1. Forward pass for Student to get logits and sow its intermediate features\n",
        "    student_logits = student_model(images)\n",
        "    student_sown_state = nnx.state(student_model, nnx.Intermediate) # Get all Intermediate variables\n",
        "    student_fm_raw = student_sown_state['light_feature_map'].value[0]\n",
        "    student_flattened_features = student_fm_raw.reshape((student_fm_raw.shape[0], -1))\n",
        "    # student_flattened_features shape: (B, 1024) for LightNN\n",
        "\n",
        "    # 2. Standard Cross-Entropy loss for student\n",
        "    ce_loss = optax.softmax_cross_entropy_with_integer_labels(\n",
        "        logits=student_logits, labels=true_labels\n",
        "    ).mean()\n",
        "\n",
        "    # 3. Forward pass for Teacher (in eval mode) to sow its intermediate features\n",
        "    _ = teacher_model(images)\n",
        "    teacher_sown_state = nnx.state(teacher_model, nnx.Intermediate)\n",
        "    teacher_fm_raw = teacher_sown_state['deep_feature_map'].value[0]\n",
        "    teacher_flattened_features_full = teacher_fm_raw.reshape((teacher_fm_raw.shape[0], -1))\n",
        "    # teacher_flattened_features_full shape: (B, 2048) for DeepNN\n",
        "\n",
        "    # 4. Dimensionality matching: Pool teacher's flattened features down to student's dimension\n",
        "    # Teacher: 2048 features, Student: 1024 features. Pooling factor = 2.\n",
        "    if teacher_flattened_features_full.shape[-1] == 2 * student_flattened_features.shape[-1]:\n",
        "        pool_factor = 2\n",
        "        # Reshape for 1D pooling: (B, num_features) -> (B, num_features/pool_factor, pool_factor)\n",
        "        # Then take the mean over the last axis.\n",
        "        teacher_reshaped_for_pool = teacher_flattened_features_full.reshape(\n",
        "            (teacher_flattened_features_full.shape[0], -1, pool_factor)\n",
        "        )\n",
        "        teacher_pooled_features = jnp.mean(teacher_reshaped_for_pool, axis=-1)\n",
        "    elif teacher_flattened_features_full.shape[-1] == student_flattened_features.shape[-1]:\n",
        "        # Dimensions already match, no pooling needed (should not happen with current models)\n",
        "        teacher_pooled_features = teacher_flattened_features_full\n",
        "    else:\n",
        "        raise ValueError(f\"Teacher feature dim {teacher_flattened_features_full.shape[-1]} \"\n",
        "                         f\"cannot be easily pooled to match student dim {student_flattened_features.shape[-1]} \"\n",
        "                         f\"with a simple factor of 2 pooling.\")\n",
        "\n",
        "    # teacher_pooled_features should now be (B, 1024)\n",
        "\n",
        "    # 5. Cosine Similarity Loss\n",
        "    cos_loss = cosine_similarity_loss_fn(student_flattened_features, teacher_pooled_features)\n",
        "\n",
        "    # 6. Combined loss\n",
        "    total_loss = (ce_student_weight * ce_loss) + (cosine_loss_weight * cos_loss)\n",
        "\n",
        "    return total_loss, student_logits\n",
        "\n",
        "@nnx.jit\n",
        "def train_step_cosine_pooled_teacher(\n",
        "    student_sow_model: ModifiedLight,\n",
        "    optimizer_student_cosine_pt: nnx.Optimizer,\n",
        "    teacher_sow_model: ModifiedDeep, # Pre-trained teacher, used in eval\n",
        "    metrics_aggregator: nnx.MultiMetric,\n",
        "    batch: Tuple[jax.Array, jax.Array],\n",
        "    ce_weight: float,\n",
        "    cosine_weight: float\n",
        "):\n",
        "    \"\"\"\n",
        "    Training step with CE loss and Cosine feature distillation loss (teacher pooled).\n",
        "    \"\"\"\n",
        "    def loss_fn_wrapper(model_to_diff, teacher_model): # model_to_diff will be student_sow_model\n",
        "        return combined_loss_logits_features_cosine_pooled_teacher(\n",
        "            model_to_diff, # Student model\n",
        "            teacher_model,\n",
        "            batch,\n",
        "            ce_weight,\n",
        "            cosine_weight\n",
        "        )\n",
        "\n",
        "    grad_fn = nnx.value_and_grad(loss_fn_wrapper, has_aux=True) # has_aux for (loss, logits)\n",
        "\n",
        "    (loss, student_logits_for_metric), grads = grad_fn(student_sow_model, teacher_sow_model)\n",
        "\n",
        "    metrics_aggregator.update(loss=loss, logits=student_logits_for_metric, labels=batch[1])\n",
        "    optimizer_student_cosine_pt.update(grads) # Updates student_sow_model in-place\n"
      ],
      "metadata": {
        "id": "kZG0ojSoWuhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_cosine_pooled_distillation(\n",
        "    student_model_to_train: ModifiedLight,\n",
        "    teacher_model_for_guidance: ModifiedDeep,\n",
        "    optax_optimizer: optax.GradientTransformation,\n",
        "    train_ds: Any,\n",
        "    test_ds: Any,\n",
        "    num_epochs: int,\n",
        "    steps_per_epoch_train: int,\n",
        "    steps_per_epoch_test: int,\n",
        "    ce_weight: float,\n",
        "    cosine_weight: float,\n",
        "    eval_every_epochs: int = 1,\n",
        "    model_name: str = \"Student_Cosine_PooledTeacher\"\n",
        ") -> Tuple[nnx.Module, Dict[str, list]]:\n",
        "\n",
        "    optimizer = nnx.Optimizer(student_model_to_train, optax_optimizer)\n",
        "\n",
        "    train_metrics_aggregator = nnx.MultiMetric(\n",
        "        loss=nnx.metrics.Average(\"loss\"),\n",
        "        accuracy=nnx.metrics.Accuracy()\n",
        "    )\n",
        "    eval_metrics_aggregator = nnx.MultiMetric( # For student's performance on true labels\n",
        "        loss=nnx.metrics.Average(\"loss\"),\n",
        "        accuracy=nnx.metrics.Accuracy()\n",
        "    )\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_accuracy': [],\n",
        "        'test_loss': [], 'test_accuracy': []\n",
        "    }\n",
        "\n",
        "    total_training_steps = num_epochs * steps_per_epoch_train\n",
        "    print(f\"\\nStarting distillation training for {model_name} for {num_epochs} epochs...\")\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=f\"Training {model_name}\"):\n",
        "        student_model_to_train.train()\n",
        "        teacher_model_for_guidance.eval()\n",
        "        train_metrics_aggregator.reset()\n",
        "        train_epoch_bar = tqdm(iter(train_ds), total=steps_per_epoch_train,\n",
        "                               desc=f\"Epoch {epoch+1}/{num_epochs} [Distill Train]\",\n",
        "                               leave=False)\n",
        "        for batch in train_epoch_bar:\n",
        "            batch_images, batch_labels = batch\n",
        "            batch_tuple = (jnp.asarray(batch_images), jnp.asarray(batch_labels))\n",
        "\n",
        "            train_step_cosine_pooled_teacher(\n",
        "                student_model_to_train,\n",
        "                optimizer,\n",
        "                teacher_model_for_guidance,\n",
        "                train_metrics_aggregator,\n",
        "                batch_tuple,\n",
        "                ce_weight,\n",
        "                cosine_weight\n",
        "            )\n",
        "\n",
        "        computed_train_metrics = train_metrics_aggregator.compute()\n",
        "        history['train_loss'].append(computed_train_metrics['loss'].item())\n",
        "        history['train_accuracy'].append(computed_train_metrics['accuracy'].item())\n",
        "        tqdm.write(f\"{model_name} - Epoch {epoch+1} Training: Avg Loss: {computed_train_metrics['loss']:.4f}, Avg Acc: {computed_train_metrics['accuracy']:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % eval_every_epochs == 0 or (epoch + 1) == num_epochs:\n",
        "            student_model_to_train.eval()\n",
        "            eval_metrics_aggregator.reset()\n",
        "            eval_epoch_bar = tqdm(iter(test_ds), total=steps_per_epoch_test,\n",
        "                                  desc=f\"Epoch {epoch+1}/{num_epochs} [Distill Eval]\",\n",
        "                                  leave=False)\n",
        "            for eval_batch in eval_epoch_bar:\n",
        "                eval_batch_images, eval_batch_labels = eval_batch\n",
        "                eval_batch_tuple = (jnp.asarray(eval_batch_images), jnp.asarray(eval_batch_labels))\n",
        "                # Evaluate the student model using the standard eval_step\n",
        "                eval_step(student_model_to_train, eval_metrics_aggregator, eval_batch_tuple)\n",
        "\n",
        "            computed_eval_metrics = eval_metrics_aggregator.compute()\n",
        "            history['test_loss'].append(computed_eval_metrics['loss'].item())\n",
        "            history['test_accuracy'].append(computed_eval_metrics['accuracy'].item())\n",
        "            tqdm.write(f\"{model_name} - Epoch {epoch+1} Evaluation: Avg Loss: {computed_eval_metrics['loss']:.4f}, Avg Acc: {computed_eval_metrics['accuracy']:.4f}\")\n",
        "        tqdm.write(\"-\" * 70)\n",
        "\n",
        "    print(f\"Distillation training finished for {model_name}.\")\n",
        "\n",
        "    # Plotting (same as before)\n",
        "    evaluated_test_epochs = [e + 1 for e in range(num_epochs) if (e + 1) % eval_every_epochs == 0 or (e + 1) == num_epochs]\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), history['train_loss'], label='Train Loss', marker='o')\n",
        "    if history['test_loss']:\n",
        "        plt.plot(evaluated_test_epochs, history['test_loss'], label='Test Loss', marker='x', linestyle='--')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'{model_name}: Loss'); plt.legend(); plt.grid(True)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, num_epochs + 1), history['train_accuracy'], label='Train Accuracy', marker='o')\n",
        "    if history['test_accuracy']:\n",
        "        plt.plot(evaluated_test_epochs, history['test_accuracy'], label='Test Accuracy', marker='x', linestyle='--')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title(f'{model_name}: Accuracy'); plt.legend(); plt.grid(True)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    return student_model_to_train, history\n",
        "\n"
      ],
      "metadata": {
        "id": "Vhi3zNkkhhUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"Preparing for Knowledge Distillation Training\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "student_model_kd = LightNN_NNX(num_classes=NUM_CLASSES, rngs=student_rngs)\n",
        "print(\"Student model for distillation initialized with the same initial parameters as baseline student.\")\n",
        "\n",
        "# 3. Define hyperparameters for distillation\n",
        "CE_STUDENT_WEIGHT_COSINE_PT = 0.25 # Weight for student's own CE loss\n",
        "COSINE_LOSS_WEIGHT_PT = 0.75     # Weight for cosine similarity loss\n",
        "\n",
        "# 4. Create an optimizer for this new student model\n",
        "student_cosine_pt_optimizer = optax.adam(learning_rate=LEARNING_RATE) # Can be same or different LR\n",
        "\n",
        "# 5. Update teacher_model_modified with teacher_model weights\n",
        "nnx.update(teacher_model_cosine_pt, nnx.state(teacher_model))\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"Training Student with Cosine Distillation (Teacher Feature Pooling)\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "restored = False\n",
        "try:\n",
        "  restore_model(student_model_cosine_pt, \"student_cosine_pt_final\")\n",
        "  trained_student_cosine_pt = student_model_kd\n",
        "  restored = True\n",
        "except Exception as e:\n",
        "  print(f\"Restore failed: {e}\")\n",
        "  restored=False\n",
        "\n",
        "if not restored:\n",
        "  trained_student_cosine_pt, student_cosine_pt_history = train_and_evaluate_cosine_pooled_distillation(\n",
        "      student_model_to_train=student_model_cosine_pt,\n",
        "      teacher_model_for_guidance=teacher_model_cosine_pt,\n",
        "      optax_optimizer=student_cosine_pt_optimizer,\n",
        "      train_ds=train_ds,\n",
        "      test_ds=test_ds,\n",
        "      num_epochs=NUM_EPOCHS_STUDENT, # Same number of epochs as baseline student\n",
        "      steps_per_epoch_train=steps_per_epoch_train,\n",
        "      steps_per_epoch_test=steps_per_epoch_test,\n",
        "      ce_weight=CE_STUDENT_WEIGHT_COSINE_PT,\n",
        "      cosine_weight=COSINE_LOSS_WEIGHT_PT,\n",
        "  )"
      ],
      "metadata": {
        "id": "0mztDLY9idI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  student_cosine_pt_save_path = os.path.join(checkpoint_dir, \"student_cosine_pt_final\")\n",
        "  ocp.StandardCheckpointer().save(student_cosine_pt_save_path, nnx.state(trained_student_cosine_pt, nnx.Param))\n",
        "  print(f\"Student model parameters saved to {student_cosine_pt_save_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Could not save student model cosine pt: {e}\")"
      ],
      "metadata": {
        "id": "UFr8q95Zj_7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /tmp/flax_nnx_kd_checkpoints/student_cosine_pt_final.zip /tmp/flax_nnx_kd_checkpoints/student_cosine_pt_final\n",
        "\n",
        "files.download(\"/tmp/flax_nnx_kd_checkpoints/student_cosine_pt_final.zip\")"
      ],
      "metadata": {
        "id": "uF3mFSu-l3SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store results for final comparison table\n",
        "baseline_accuracies = compare_model_accuracies({\n",
        "    \"Teacher\": teacher_model,\n",
        "    \"Student_Baseline\": student_model,\n",
        "    \"Student_KD (Output Logits)\": student_model_kd,\n",
        "    \"Student_Cosine_PooledTeacher\": student_model_cosine_pt,\n",
        "}, test_ds)\n",
        "\n",
        "print(\"\\n--- Accuracy Summary So Far ---\")\n",
        "for model_name, acc in baseline_accuracies.items():\n",
        "    if isinstance(acc, str):\n",
        "        print(f\"{model_name}: {acc}\")\n",
        "    else:\n",
        "        print(f\"{model_name}: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "ay-ZSJ__l-0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}